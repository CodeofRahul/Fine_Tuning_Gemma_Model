# Fine_Tuning_Gemma_Model
This project demonstrates how to fine-tune the Gemma-2B language model for conversation summarization using QLoRA (Quantized Low-Rank Adaptation) on the SAMSum dataset. It leverages Hugging Face Transformers, PEFT, and BitsAndBytes libraries for efficient and effective fine-tuning.
